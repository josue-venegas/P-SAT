{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe5c621",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aba5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install rdflib\n",
    "%pip install pymongo\n",
    "%pip install google-generativeai\n",
    "%pip install timm einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "import google.generativeai as genai\n",
    "from rdflib import Graph, Namespace\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b2c20c",
   "metadata": {},
   "source": [
    "# Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "RDF_FILE_PATH = \"metanettypes.ttl\"  # RDF Turtle file path. Downloaded from https://github.com/alammehwish/AmnesticForgery/blob/master/metanettypes.ttl\n",
    "API_KEY = \"AIzaSyDykQxeDJ0m7t8GTbxkWEr4SXfWZA2LVCE\"  # Replace with a valid API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87698ea4",
   "metadata": {},
   "source": [
    "# Initialize the Model and Processor\n",
    "\n",
    "We will initialize the model and processor from the `transformers` library. The model will be used to generate text based on the image, and the processor will handle inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize the model and processor\n",
    "def initialize_model_and_processor(device: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Initialize the model and processor based on device availability.\n",
    "    \n",
    "    Args:\n",
    "        device (str): The device to run the model on (\"cuda:0\" or \"cpu\").\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model, processor) - The initialized model and processor.\n",
    "    \"\"\"\n",
    "    torch_dtype = torch.float16 if device == \"cuda:0\" else torch.float32\n",
    "    model_name = \"microsoft/Florence-2-large\"\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch_dtype, trust_remote_code=True).to(device)\n",
    "    processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "# Initialize device and model\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, processor = initialize_model_and_processor(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b783a4",
   "metadata": {},
   "source": [
    "# Generate Meme Description\n",
    "\n",
    "We will use the model and processor to generate a description for the uploaded image, based on a prompt. This will allow us to describe the contents of the meme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate description based on image and prompt\n",
    "def generate_description(model, processor, image: Image, prompt: str, device: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a description based on the image and provided prompt.\n",
    "    \n",
    "    Args:\n",
    "        model (AutoModelForCausalLM): The pre-trained model.\n",
    "        processor (AutoProcessor): The processor for handling inputs and outputs.\n",
    "        image (Image): The input image.\n",
    "        prompt (str): The prompt for generating a description.\n",
    "        device (str): The device to run the model on (\"cuda:0\" or \"cpu\").\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated description.\n",
    "    \"\"\"\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=4096,\n",
    "        num_beams=3,\n",
    "        do_sample=False\n",
    "    )\n",
    "    \n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    parsed_answer = processor.post_process_generation(generated_text, task=prompt, image_size=(image.width, image.height))\n",
    "    \n",
    "    return parsed_answer[prompt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4ab37",
   "metadata": {},
   "source": [
    "# Configure Google Generative AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to configure Google Generative AI API\n",
    "def configure_google_ai(api_key: str) -> None:\n",
    "    \"\"\"\n",
    "    Configure the Google Generative AI API with the provided API key.\n",
    "    \n",
    "    Args:\n",
    "        api_key (str): The API key for Google Generative AI.\n",
    "    \"\"\"\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "# Configure Google Generative AI\n",
    "configure_google_ai(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f4b28",
   "metadata": {},
   "source": [
    "# Load RDF Frames\n",
    "\n",
    "Now, we will load the available meme frames from an RDF (Turtle) file. This data contains predefined frames for memes that we can match against the generated description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load frames from an RDF file\n",
    "def load_frames(rdf_file: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Load frames from an RDF Turtle file.\n",
    "    \n",
    "    Args:\n",
    "        rdf_file (str): Path to the RDF Turtle file.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of frame names extracted from the RDF file.\n",
    "    \"\"\"\n",
    "    g = Graph()\n",
    "    g.parse(rdf_file, format=\"turtle\")\n",
    "    \n",
    "    framedata = Namespace(\"https://w3id.org/framester/metanet/frames/\")\n",
    "    metanet = Namespace(\"https://w3id.org/framester/metanet/schema/\")\n",
    "    rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    \n",
    "    frames = [str(frame).split(\"/\")[-1] for frame in g.subjects(predicate=rdf.type, object=metanet.Frame)]\n",
    "    return frames\n",
    "\n",
    "# Load frames from the RDF file\n",
    "frames = load_frames(RDF_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163400b1",
   "metadata": {},
   "source": [
    "# Query Generative AI for Detailed description, Fitted frames and its Justification\n",
    "\n",
    "Using the description generated from the image and the available frames, we will query the generative model to identify which frames best fit the meme description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "325a6c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model_with_explanation_and_fitted_frames(meme_description: str, frames: List[str], meme_context: str = None, meme_lang: str = \"EN\") -> dict:\n",
    "    \"\"\"\n",
    "    Query the generative model for an explanation of the meme, the frames that best fit the explanation,\n",
    "    and why those frames were chosen.\n",
    "\n",
    "    Args:\n",
    "        meme_description (str): The meme description.\n",
    "        frames (List[str]): The list of available frames.\n",
    "        meme_context (str): The meme context (optional).\n",
    "        meme_lang (str): The language of the meme (default is \"EN\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with keys 'explanation', 'fitted_frames', and 'reasoning'.\n",
    "    \"\"\"\n",
    "    \n",
    "    frames_text = \", \".join(frames)\n",
    "    \n",
    "    if meme_context is None:\n",
    "        prompt = (\n",
    "            f\"Here is a description for a specific meme: '{meme_description}'\\n\\n\"\n",
    "            f\"The following frames are available: {frames_text}.\\n\"\n",
    "            \"Based on the previous description, provide a detailed explanation of the meme.\\n\"\n",
    "            \"On the next line, explicitly write: 'Fitted Frames:' followed by the available frames in which this meme fits, separated by commas.\\n\"\n",
    "            \"Then, for EACH fitted frame, provide a separate explanation of WHY that specific frame was chosen, using the following format:\\n\"\n",
    "            \"- Frame Name: Explanation for this frame\\n\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = (\n",
    "            f\"Here is the context for a specific meme: '{meme_context}'\\n\\n\"\n",
    "            f\"Here is the meme description: '{meme_description}'\\n\\n\"\n",
    "            f\"The following frames are available: {frames_text}.\\n\"\n",
    "            \"Based on the previous context and description, provide a detailed explanation of the meme.\\n\"\n",
    "            \"On the next line, explicitly write: 'Fitted Frames:' followed by the available frames in which this meme fits, separated by commas.\\n\"\n",
    "            \"Then, for EACH fitted frame, provide a separate explanation of WHY that specific frame was chosen, using the following format:\\n\"\n",
    "            \"- Frame Name: Explanation for this frame\\n\"\n",
    "        )\n",
    "    \n",
    "    if meme_lang == \"ES\":\n",
    "        prompt += (\n",
    "            \"\\n\\n\"\n",
    "            \"Please note that the meme was written in Spanish, so the translation provided in the meme description may not always be accurate. In that case, ignore it and translate it by your own.\\n\"\n",
    "        )\n",
    "    elif meme_lang == \"FR\":\n",
    "        prompt += (\n",
    "            \"\\n\\n\"\n",
    "            \"Please note that the meme was written in French, so the translation provided in the meme description may not always be accurate. In that case, ignore it and translate it by your own.\\n\"\n",
    "        )\n",
    "    \n",
    "    large_language_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = large_language_model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=genai.types.GenerationConfig(temperature=1.2)\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    response_text = response.text.strip()\n",
    "    explanation = \"\"\n",
    "    fitted_frames = {}\n",
    "    \n",
    "    if \"Fitted Frames:\" in response_text:\n",
    "        parts = response_text.split(\"Fitted Frames:\")\n",
    "        explanation = parts[0].strip()\n",
    "        frame_explanations = parts[1].strip().split('\\n')\n",
    "        for frame_explanation in frame_explanations:\n",
    "            if \": \" in frame_explanation and frame_explanation.startswith('- '):\n",
    "                frame, reason = frame_explanation[2:].split(\": \", 1)\n",
    "                fitted_frames[frame.strip()] = reason.strip()\n",
    "                \n",
    "    else:\n",
    "        # If the format is incorrect, generate a follow-up prompt\n",
    "        follow_up_prompt = (\n",
    "            f\"The response did not follow the expected format. Please reformat it as follows:\\n\"\n",
    "            \"1. Provide a detailed explanation of the meme.\\n\"\n",
    "            \"2. Explicitly write: 'Fitted Frames:' followed by the available frames in which this meme fits, separated by commas.\\n\"\n",
    "            \"3. For EACH fitted frame, provide an explanation using this format:\\n\"\n",
    "            \"- Frame Name: Explanation for this frame\\n\"\n",
    "            \"Here is the original prompt for reference:\\n\"\n",
    "            f\"{prompt}\"\n",
    "        )\n",
    "        \n",
    "        response = large_language_model.generate_content(\n",
    "            follow_up_prompt,\n",
    "            generation_config=genai.types.GenerationConfig(temperature=1.2)\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        response_text = response.text.strip()\n",
    "        \n",
    "        if \"Fitted Frames:\" in response_text:\n",
    "            parts = response_text.split(\"Fitted Frames:\")\n",
    "            explanation = parts[0].strip()\n",
    "            frame_explanations = parts[1].strip().split('\\n')\n",
    "            for frame_explanation in frame_explanations:\n",
    "                if \": \" in frame_explanation and frame_explanation.startswith('- '):\n",
    "                    frame, reason = frame_explanation[2:].split(\": \", 1)\n",
    "                    fitted_frames[frame.strip()] = reason.strip()\n",
    "        else:\n",
    "            explanation = response_text\n",
    "            fitted_frames = {}\n",
    "    \n",
    "    # Sometimes the LLM model generates extra frames, so we filter them out\n",
    "    filtered_frames = {}\n",
    "    for frame, reason in fitted_frames.items():\n",
    "        if frame in frames:\n",
    "            filtered_frames[frame] = reason\n",
    "\n",
    "    return {\"explanation\": explanation, \"fitted_frames\": filtered_frames}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602bce83",
   "metadata": {},
   "source": [
    "# Generate Match Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "082eab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a match vector between the frames and the fitted frames\n",
    "def generate_match_vector(frames: List[str], fitted_frames: List[str]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Generate a match vector to compare the frames with the fitted frames.\n",
    "    \n",
    "    Args:\n",
    "        frames (List[str]): The list of available frames.\n",
    "        fitted_frames (List[str]): The list of frames that fit the meme description.\n",
    "    \n",
    "    Returns:\n",
    "        List[int]: A match vector indicating which frames fit.\n",
    "    \"\"\"\n",
    "    return [1 if frame in fitted_frames else 0 for frame in frames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc4555",
   "metadata": {},
   "source": [
    "# Connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94985e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "connection_string = 'mongodb+srv://api_user:Eni4pojp5L6d8uoy@cluster0.1zf1w.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0'\n",
    "client = MongoClient(connection_string)\n",
    "db = client['memes']\n",
    "imgflip_collection = db['imgflip']\n",
    "kym_collection = db['kym']\n",
    "reddit_spanish_collection = db['reddit-spanish-memes']\n",
    "reddit_french_collection = db['reddit-french-memes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af50ea",
   "metadata": {},
   "source": [
    "# Main code\n",
    "\n",
    "After having run all the above code, we can run this section to do the analysis on several images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae64172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch images from URLs\n",
    "def fetch_images(origin, collection):\n",
    "    for doc in collection.find():\n",
    "        if origin == \"imgflip\" or origin == \"kym\":\n",
    "            image_url = doc.get('image_url')\n",
    "        \n",
    "        elif origin == \"reddit-spanish-memes\" or origin == \"reddit-french-memes\":\n",
    "            image_url = doc.get('url')\n",
    "        \n",
    "        if not image_url:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(image_url)\n",
    "            response.raise_for_status()\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            yield doc, image\n",
    "        except Exception as e:\n",
    "            #print(f\"Failed to fetch image from {image_url}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Function to process images and add attributes\n",
    "def add_attributes(origin, collection, model, processor, device):\n",
    "    # Wrap the fetch_images generator with tqdm to track progress\n",
    "    total_docs = collection.count_documents({})  # Get the total number of documents\n",
    "    for doc, image in tqdm(fetch_images(origin, collection), desc=\"Assigning attributes\", total=total_docs):\n",
    "        try:\n",
    "            # Skip documents that already have the generated attributes\n",
    "            if doc.get(\"gen_description\") and doc.get(\"gen_explanation\") and doc.get(\"gen_fitted_frames\"):\n",
    "                continue\n",
    "            \n",
    "            # Generate values\n",
    "            task_prompt = \"<MORE_DETAILED_CAPTION>\"\n",
    "            meme_description = generate_description(model, processor, image, task_prompt, device)\n",
    "            \n",
    "            if origin == \"imgflip\":\n",
    "                result = query_model_with_explanation_and_fitted_frames(meme_description, frames)\n",
    "            elif origin == \"kym\":\n",
    "                meme_context = doc.get(\"description\")\n",
    "                result = query_model_with_explanation_and_fitted_frames(meme_description, frames, meme_context)\n",
    "            elif origin == \"reddit-spanish-memes\":\n",
    "                result = query_model_with_explanation_and_fitted_frames(meme_description, frames, meme_lang=\"ES\")\n",
    "            elif origin == \"reddit-french-memes\":\n",
    "                result = query_model_with_explanation_and_fitted_frames(meme_description, frames, meme_lang=\"FR\")\n",
    "            \n",
    "            # Extract values\n",
    "            explanation = result[\"explanation\"]\n",
    "            fitted_frames = result[\"fitted_frames\"]\n",
    "            \n",
    "            # Fitted frames is a dictionary, convert it to a list of dictionaries\n",
    "            # Each dictionary contains the frame name and the reasoning\n",
    "            fitted_frames = [{\"name\": frame, \"reasoning\": reasoning} for frame, reasoning in fitted_frames.items()]\n",
    "\n",
    "            # Update document in MongoDB\n",
    "            collection.update_one(\n",
    "                {\"_id\": doc[\"_id\"]},  # Match document by ID\n",
    "                {\"$set\": {\n",
    "                    \"gen_description\": meme_description,\n",
    "                    \"gen_explanation\": explanation,\n",
    "                    \"gen_fitted_frames\": fitted_frames,\n",
    "                }}\n",
    "            )           \n",
    "        except Exception as e:\n",
    "            #print(f\"Failed to process and update document with ID {doc['_id']}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Run the pipeline\n",
    "print(\"Starting the meme analysis pipeline...\")\n",
    "print(\"Loaded Frames:\", len(frames))\n",
    "add_attributes(\"imgflip\", imgflip_collection, model, processor, device)\n",
    "add_attributes(\"kym\", kym_collection, model, processor, device)\n",
    "add_attributes(\"reddit-spanish-memes\", reddit_spanish_collection, model, processor, device)\n",
    "add_attributes(\"reddit-french-memes\", reddit_french_collection, model, processor, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
