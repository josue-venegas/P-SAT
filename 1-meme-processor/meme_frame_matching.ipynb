{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe5c621",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aba5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install rdflib\n",
    "%pip install pymongo\n",
    "%pip install google-generativeai\n",
    "%pip install timm einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "import google.generativeai as genai\n",
    "from rdflib import Graph, Namespace\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b2c20c",
   "metadata": {},
   "source": [
    "# Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "RDF_FILE_PATH = \"metanettypes.ttl\"  # RDF Turtle file path. Downloaded from https://github.com/alammehwish/AmnesticForgery/blob/master/metanettypes.ttl\n",
    "API_KEY = \"AIzaSyDykQxeDJ0m7t8GTbxkWEr4SXfWZA2LVCE\"  # Replace with a valid API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87698ea4",
   "metadata": {},
   "source": [
    "# Initialize the Model and Processor\n",
    "\n",
    "We will initialize the model and processor from the `transformers` library. The model will be used to generate text based on the image, and the processor will handle inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize the model and processor\n",
    "def initialize_model_and_processor(device: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Initialize the model and processor based on device availability.\n",
    "    \n",
    "    Args:\n",
    "        device (str): The device to run the model on (\"cuda:0\" or \"cpu\").\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (model, processor) - The initialized model and processor.\n",
    "    \"\"\"\n",
    "    torch_dtype = torch.float16 if device == \"cuda:0\" else torch.float32\n",
    "    model_name = \"microsoft/Florence-2-large\"\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch_dtype, trust_remote_code=True).to(device)\n",
    "    processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "# Initialize device and model\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, processor = initialize_model_and_processor(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b783a4",
   "metadata": {},
   "source": [
    "# Generate Meme Description\n",
    "\n",
    "We will use the model and processor to generate a description for the uploaded image, based on a prompt. This will allow us to describe the contents of the meme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate description based on image and prompt\n",
    "def generate_description(model, processor, image: Image, prompt: str, device: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a description based on the image and provided prompt.\n",
    "    \n",
    "    Args:\n",
    "        model (AutoModelForCausalLM): The pre-trained model.\n",
    "        processor (AutoProcessor): The processor for handling inputs and outputs.\n",
    "        image (Image): The input image.\n",
    "        prompt (str): The prompt for generating a description.\n",
    "        device (str): The device to run the model on (\"cuda:0\" or \"cpu\").\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated description.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(prompt)\n",
    "    \n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=4096,\n",
    "        num_beams=3,\n",
    "        do_sample=False\n",
    "    )\n",
    "    \n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    parsed_answer = processor.post_process_generation(generated_text, task=prompt, image_size=(image.width, image.height))\n",
    "    \n",
    "    return parsed_answer[prompt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4ab37",
   "metadata": {},
   "source": [
    "# Configure Google Generative AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to configure Google Generative AI API\n",
    "def configure_google_ai(api_key: str) -> None:\n",
    "    \"\"\"\n",
    "    Configure the Google Generative AI API with the provided API key.\n",
    "    \n",
    "    Args:\n",
    "        api_key (str): The API key for Google Generative AI.\n",
    "    \"\"\"\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "# Configure Google Generative AI\n",
    "configure_google_ai(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f4b28",
   "metadata": {},
   "source": [
    "# Load RDF Frames\n",
    "\n",
    "Now, we will load the available meme frames from an RDF (Turtle) file. This data contains predefined frames for memes that we can match against the generated description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load frames from an RDF file\n",
    "def load_frames(rdf_file: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Load frames from an RDF Turtle file.\n",
    "    \n",
    "    Args:\n",
    "        rdf_file (str): Path to the RDF Turtle file.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of frame names extracted from the RDF file.\n",
    "    \"\"\"\n",
    "    g = Graph()\n",
    "    g.parse(rdf_file, format=\"turtle\")\n",
    "    \n",
    "    framedata = Namespace(\"https://w3id.org/framester/metanet/frames/\")\n",
    "    metanet = Namespace(\"https://w3id.org/framester/metanet/schema/\")\n",
    "    rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    \n",
    "    frames = [str(frame).split(\"/\")[-1] for frame in g.subjects(predicate=rdf.type, object=metanet.Frame)]\n",
    "    return frames\n",
    "\n",
    "# Load frames from the RDF file\n",
    "frames = load_frames(RDF_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163400b1",
   "metadata": {},
   "source": [
    "# Query Generative AI for Detailed description, Fitted frames and its Justification\n",
    "\n",
    "Using the description generated from the image and the available frames, we will query the generative model to identify which frames best fit the meme description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "325a6c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model_with_explanation_and_fitted_frames(meme_description: str, frames: List[str], meme_context: str = None, meme_lang: str = \"EN\") -> dict:\n",
    "    \"\"\"\n",
    "    Query the generative model for an explanation of the meme, the frames that best fit the explanation,\n",
    "    and why those frames were chosen.\n",
    "\n",
    "    Args:\n",
    "        meme_description (str): The meme description.\n",
    "        frames (List[str]): The list of available frames.\n",
    "        meme_context (str): The meme context (optional).\n",
    "        meme_lang (str): The language of the meme (default is \"EN\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with keys 'explanation', 'fitted_frames', and 'reasoning'.\n",
    "    \"\"\"\n",
    "    \n",
    "    frames_text = \", \".join(frames)\n",
    "    \n",
    "    if meme_context is None:\n",
    "        prompt = (\n",
    "            f\"Here is a description for a specific meme: '{meme_description}'\\n\\n\"\n",
    "            f\"The following frames are available: {frames_text}.\\n\"\n",
    "            \"Based on the previous description, provide a detailed explanation of the meme.\\n\"\n",
    "            \"On the next line, explicitly write: 'Fitted Frames:' followed by the available frames in which this meme fits, separated by commas.\\n\"\n",
    "            \"Then, for EACH fitted frame, provide a separate explanation of WHY that specific frame was chosen, using the following format:\\n\"\n",
    "            \"- Frame Name: Explanation for this frame\\n\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = (\n",
    "            f\"Here is the context for a specific meme: '{meme_context}'\\n\\n\"\n",
    "            f\"Here is the meme description: '{meme_description}'\\n\\n\"\n",
    "            f\"The following frames are available: {frames_text}.\\n\"\n",
    "            \"Based on the previous context and description, provide a detailed explanation of the meme.\\n\"\n",
    "            \"On the next line, explicitly write: 'Fitted Frames:' followed by the available frames in which this meme fits, separated by commas.\\n\"\n",
    "            \"Then, for EACH fitted frame, provide a separate explanation of WHY that specific frame was chosen, using the following format:\\n\"\n",
    "            \"- Frame Name: Explanation for this frame\\n\"\n",
    "        )\n",
    "    \n",
    "    if meme_lang == \"ES\":\n",
    "        prompt += (\n",
    "            \"\\n\\n\"\n",
    "            \"Please note that the meme was written in Spanish, so the translation provided in the meme description may not always be accurate. In that case, ignore it and translate it by your own.\\n\"\n",
    "        )\n",
    "    elif meme_lang == \"FR\":\n",
    "        prompt += (\n",
    "            \"\\n\\n\"\n",
    "            \"Please note that the meme was written in French, so the translation provided in the meme description may not always be accurate. In that case, ignore it and translate it by your own.\\n\"\n",
    "        )\n",
    "    \n",
    "    print(prompt)\n",
    "    print(\"*\" * 100)\n",
    "    large_language_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = large_language_model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=genai.types.GenerationConfig(temperature=1.2)\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    response_text = response.text.strip()\n",
    "    explanation = \"\"\n",
    "    fitted_frames = {}\n",
    "    \n",
    "    if \"Fitted Frames:\" in response_text:\n",
    "        parts = response_text.split(\"Fitted Frames:\")\n",
    "        explanation = parts[0].strip()\n",
    "        frame_explanations = parts[1].strip().split('\\n')\n",
    "        for frame_explanation in frame_explanations:\n",
    "            if \": \" in frame_explanation and frame_explanation.startswith('- '):\n",
    "                frame, reason = frame_explanation[2:].split(\": \", 1)\n",
    "                fitted_frames[frame.strip()] = reason.strip()\n",
    "                \n",
    "    else:\n",
    "        # If the format is incorrect, generate a follow-up prompt\n",
    "        follow_up_prompt = (\n",
    "            f\"The response did not follow the expected format. Please reformat it as follows:\\n\"\n",
    "            \"1. Provide a detailed explanation of the meme.\\n\"\n",
    "            \"2. Explicitly write: 'Fitted Frames:' followed by the available frames in which this meme fits, separated by commas.\\n\"\n",
    "            \"3. For EACH fitted frame, provide an explanation using this format:\\n\"\n",
    "            \"- Frame Name: Explanation for this frame\\n\"\n",
    "            \"Here is the original prompt for reference:\\n\"\n",
    "            f\"{prompt}\"\n",
    "        )\n",
    "        \n",
    "        response = large_language_model.generate_content(\n",
    "            follow_up_prompt,\n",
    "            generation_config=genai.types.GenerationConfig(temperature=1.2)\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        response_text = response.text.strip()\n",
    "        \n",
    "        if \"Fitted Frames:\" in response_text:\n",
    "            parts = response_text.split(\"Fitted Frames:\")\n",
    "            explanation = parts[0].strip()\n",
    "            frame_explanations = parts[1].strip().split('\\n')\n",
    "            for frame_explanation in frame_explanations:\n",
    "                if \": \" in frame_explanation and frame_explanation.startswith('- '):\n",
    "                    frame, reason = frame_explanation[2:].split(\": \", 1)\n",
    "                    fitted_frames[frame.strip()] = reason.strip()\n",
    "        else:\n",
    "            explanation = response_text\n",
    "            fitted_frames = {}\n",
    "    \n",
    "    # Sometimes the LLM model generates extra frames, so we filter them out\n",
    "    filtered_frames = {}\n",
    "    for frame, reason in fitted_frames.items():\n",
    "        if frame in frames:\n",
    "            filtered_frames[frame] = reason\n",
    "\n",
    "    return {\"explanation\": explanation, \"fitted_frames\": filtered_frames}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602bce83",
   "metadata": {},
   "source": [
    "# Generate Match Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "082eab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a match vector between the frames and the fitted frames\n",
    "def generate_match_vector(frames: List[str], fitted_frames: List[str]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Generate a match vector to compare the frames with the fitted frames.\n",
    "    \n",
    "    Args:\n",
    "        frames (List[str]): The list of available frames.\n",
    "        fitted_frames (List[str]): The list of frames that fit the meme description.\n",
    "    \n",
    "    Returns:\n",
    "        List[int]: A match vector indicating which frames fit.\n",
    "    \"\"\"\n",
    "    return [1 if frame in fitted_frames else 0 for frame in frames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc4555",
   "metadata": {},
   "source": [
    "# Connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94985e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "connection_string = 'mongodb+srv://api_user:Eni4pojp5L6d8uoy@cluster0.1zf1w.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0'\n",
    "client = MongoClient(connection_string)\n",
    "db = client['memes']\n",
    "imgflip_collection = db['imgflip']\n",
    "kym_collection = db['kym']\n",
    "reddit_spanish_collection = db['reddit-spanish-memes']\n",
    "reddit_french_collection = db['reddit-french-memes']\n",
    "local_templates = db['local-templates']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af50ea",
   "metadata": {},
   "source": [
    "# Main code\n",
    "\n",
    "After having run all the above code, we can run this section to do the analysis on several images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6cef3",
   "metadata": {},
   "source": [
    "### Frame fitting using already existing MongoDB collections\n",
    "The memes are updated in the MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae64172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch images from URLs\n",
    "def fetch_images(origin, collection):\n",
    "    for doc in collection.find():\n",
    "        if origin == \"imgflip\" or origin == \"kym\" or origin == \"local-templates\":\n",
    "            image_url = doc.get('image_url')\n",
    "        \n",
    "        elif origin == \"reddit-spanish-memes\" or origin == \"reddit-french-memes\":\n",
    "            image_url = doc.get('url')\n",
    "        \n",
    "        if not image_url:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(image_url)\n",
    "            response.raise_for_status()\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            yield doc, image\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch image from {image_url}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Function to process images and add attributes\n",
    "def add_attributes(origin, collection, model, processor, device):\n",
    "    # Wrap the fetch_images generator with tqdm to track progress\n",
    "    total_docs = collection.count_documents({})  # Get the total number of documents\n",
    "    for doc, image in tqdm(fetch_images(origin, collection), desc=\"Assigning attributes\", total=total_docs):\n",
    "        try:\n",
    "            # Skip documents that already have the generated attributes\n",
    "            if doc.get(\"gen_description\") and doc.get(\"gen_explanation\") and doc.get(\"gen_fitted_frames\"):\n",
    "                continue\n",
    "            \n",
    "            # Generate values\n",
    "            task_prompt = \"<MORE_DETAILED_CAPTION>\"\n",
    "            meme_description = generate_description(model, processor, image, task_prompt, device)\n",
    "            \n",
    "            if origin == \"imgflip\":\n",
    "                result = query_model_with_explanation_and_fitted_frames(meme_description, frames)\n",
    "            elif origin == \"kym\" or origin == \"local-templates\":\n",
    "                meme_context = doc.get(\"description\")\n",
    "                result = query_model_with_explanation_and_fitted_frames(meme_description, frames, meme_context)\n",
    "            elif origin == \"reddit-spanish-memes\":\n",
    "                result = query_model_with_explanation_and_fitted_frames(meme_description, frames, meme_lang=\"ES\")\n",
    "            elif origin == \"reddit-french-memes\":\n",
    "                result = query_model_with_explanation_and_fitted_frames(meme_description, frames, meme_lang=\"FR\")\n",
    "            \n",
    "            # Extract values\n",
    "            explanation = result[\"explanation\"]\n",
    "            fitted_frames = result[\"fitted_frames\"]\n",
    "            \n",
    "            # Fitted frames is a dictionary, convert it to a list of dictionaries\n",
    "            # Each dictionary contains the frame name and the reasoning\n",
    "            fitted_frames = [{\"name\": frame, \"reasoning\": reasoning} for frame, reasoning in fitted_frames.items()]\n",
    "\n",
    "            # Update document in MongoDB\n",
    "            collection.update_one(\n",
    "                {\"_id\": doc[\"_id\"]},  # Match document by ID\n",
    "                {\"$set\": {\n",
    "                    \"gen_description\": meme_description,\n",
    "                    \"gen_explanation\": explanation,\n",
    "                    \"gen_fitted_frames\": fitted_frames,\n",
    "                }}\n",
    "            )           \n",
    "        except Exception as e:\n",
    "            #print(f\"Failed to process and update document with ID {doc['_id']}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Run the pipeline\n",
    "print(\"Starting the meme analysis pipeline...\")\n",
    "print(\"Loaded Frames:\", len(frames))\n",
    "#add_attributes(\"imgflip\", imgflip_collection, model, processor, device)\n",
    "#add_attributes(\"kym\", kym_collection, model, processor, device)\n",
    "#add_attributes(\"reddit-spanish-memes\", reddit_spanish_collection, model, processor, device)\n",
    "#add_attributes(\"reddit-french-memes\", reddit_french_collection, model, processor, device)\n",
    "add_attributes(\"local-templates\", local_templates, model, processor, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d844e",
   "metadata": {},
   "source": [
    "### Frame fitting using local images\n",
    "The memes are inserted into the MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of loading the images from MongoDB, load them locally from the folder ./Memes\n",
    "# Since they are anidated, search for the images in the subfolders\n",
    "\n",
    "import os\n",
    "\n",
    "meme_contexts = {\n",
    "    \"Distracted Boyfriend\": 'Distracted Boyfriend, also known as Man Looking at Other Woman, is an object labeling stock photo series in which a man looks at the backside of a woman walking by while another woman, presumably his romantic partner, looks on disapprovingly.',\n",
    "    \"Traumatized Mr. Incredible\": \"Traumatized Mr. Incredible refers to a series of comparison memes based on two images of Mr. Incredible, one an official art for The Incredibles 2 and the other a 'reverse toonified' and black-and-white version of the character that gives him an expression of a man experiencing emotional pain, similar to Withered Wojak. Starting in September 2021, the format was used together with the caption People Who Don't Know / People Who Know in comparison memes.\",\n",
    "    \"Spider-Man Pointing at Spider-Man\": \"Spider-Man Pointing at Spider-Man refers to an image from the 60's Spider-Man cartoon episode in which two people in Spider-Man costumes are pointing at each other.\",\n",
    "    \"We Are Not the Same\": 'We Are Not the Same is a catchphrase that was popularized on Twitter in the fall of 2019. The catchphrase has been used in memes that parody self-aggrandizing comparisons, such as \"You pray for me to fall, I pray for you to get back up. We are not the same.\" The parodies often end with a self-deprecating punchline. In 2021, the format regained virality with ironic image macros featuring actors Giancarlo Esposito and Mads Mikkelsen following a viral Gamer Joker meme posted in May 2021.',\n",
    "}\n",
    "\n",
    "memes_url = {\n",
    "    \"Distracted Boyfriend\": {\n",
    "        \"en_01\": \"https://drive.google.com/file/d/1g3D4K_5ajtGMrvRt1ZD4DMtiniiuAODG/view\",\n",
    "        \"en_02\": \"https://drive.google.com/file/d/1AvDz8HG_3HcBd_akSlG-MhsRLdmxgwlt/view\",\n",
    "        \"en_03\": \"https://drive.google.com/file/d/1SzeqMbqqPvnHZXCPkdeVf42Z8yDWX4GU/view\",\n",
    "        \"en_04\": \"https://drive.google.com/file/d/1ldpqVDjpDHpTgJ7RHErMwmi5IE7qYdBL/view\",\n",
    "        \"en_05\": \"https://drive.google.com/file/d/1O8OCl0auQIEX9aM1fy48YnxyBD7X2QiZ/view\",\n",
    "        \"es_01\": \"https://drive.google.com/file/d/1_S8AKV9qGDG43OUJTShHr2l5XQ8l9--F/view\",\n",
    "        \"es_02\": \"https://drive.google.com/file/d/1tb43VijH0DSSHj9GQKfKKii8rhld5wgZ/view\",\n",
    "        \"es_03\": \"https://drive.google.com/file/d/1DyhT4DkYCFxBH_XakEMrVMtGPmziiwVJ/view\",\n",
    "        \"es_04\": \"https://drive.google.com/file/d/1AChKqsVA19El5H2enje7vT-Mk6WeD9T0/view\",\n",
    "        \"es_05\": \"https://drive.google.com/file/d/1OgFHm4yAAHuSBtWdVnykRYgww66_K3WA/view\",\n",
    "        \"fr_01\": \"https://drive.google.com/file/d/1DTny79YvpAyqZaPPOuQd3CQ4Hcf65Vfj/view\",\n",
    "        \"fr_02\": \"https://drive.google.com/file/d/1jkPG9GTzWQoNnD2EnNNXCs7yvHR1cE9Q/view\",\n",
    "        \"fr_03\": \"https://drive.google.com/file/d/1_RC1pQWIRYO-6LkdS_5QAwujtY_f-3rt/view\",\n",
    "        \"fr_04\": \"https://drive.google.com/file/d/11YCvknSvBxU3gkcaoK1KTyad5l-lChbi/view\",\n",
    "        \"fr_05\": \"https://drive.google.com/file/d/1C4txwt4MGRB1ZkDK6aKFWOe4b9rvGdXu/view\",\n",
    "    },\n",
    "    \"Spider-Man Pointing at Spider-Man\": {\n",
    "        \"en_01\": \"https://drive.google.com/file/d/1BtGtbAtO2qaZs9gICrpA34BgFTbTgLYr/view\",\n",
    "        \"en_02\": \"https://drive.google.com/file/d/1ja44kBmke-QVXzM_6HBx68Tk7h_wqQdh/view\",\n",
    "        \"en_03\": \"https://drive.google.com/file/d/1R1YpVF-TBDgwqKOhnl-3ekws5GnDwaiS/view\",\n",
    "        \"en_04\": \"https://drive.google.com/file/d/1Qz9Qb3_os1ZjtgiLkSPuPXLtJRPHMACc/view\",\n",
    "        \"en_05\": \"https://drive.google.com/file/d/1QOj2AgCxPFW65UdGX50paD1Nv-NDBm7n/view\",\n",
    "        \"en_06\": \"https://drive.google.com/file/d/1QoipAD9uQoiicr17v48VvNlgjJptyZxG/view\",\n",
    "        \"es_01\": \"https://drive.google.com/file/d/1xBg2XpC4SPoZQViFcSLvrxihof96fUkF/view\",\n",
    "        \"es_02\": \"https://drive.google.com/file/d/1NH520ExWXXsCne33eHzRhtkp8T_fE0OP/view\",\n",
    "        \"es_03\": \"https://drive.google.com/file/d/1eW9jbwCwd5FmoyBL1DU3LkcGUCVyvKSa/view\",\n",
    "        \"es_04\": \"https://drive.google.com/file/d/1DJub40xyagTGEEWtRGEnTv2WITxd3Kso/view\",\n",
    "        \"es_05\": \"https://drive.google.com/file/d/1G72li8ou-zT02XFZwipYYX44FnyRLH4k/view\",\n",
    "        \"fr_01\": \"https://drive.google.com/file/d/1Y7kjGFPh62bMukcQVArIhnT--8hJ139x/view\",\n",
    "        \"fr_02\": \"https://drive.google.com/file/d/1Uk1A_u0eZc-4w6z6o7zeFzwXg-mJSiFJ/view\",\n",
    "    },\n",
    "    \"Traumatized Mr. Incredible\": {\n",
    "        \"en_01\": \"https://drive.google.com/file/d/1Y5F46IoT4MmTwBTRno-g6P-PHEwoLOa4/view\",\n",
    "        \"en_02\": \"https://drive.google.com/file/d/1_tk_Mj0d73lJS6AN-80X4eEiwnhkv-Fu/view\",\n",
    "        \"en_03\": \"https://drive.google.com/file/d/1K0pgwYuhmUbmxtL3tqJCjEKfhkSxQvKt/view\",\n",
    "        \"en_04\": \"https://drive.google.com/file/d/1t4nQwN7c0cGkN1ihpvAU2BYsTcSnYReD/view\",\n",
    "        \"en_05\": \"https://drive.google.com/file/d/1-WpgGs81M3lvbD1d6P1-2UHLxdg8dmMC/view\",\n",
    "        \"es_01\": \"https://drive.google.com/file/d/15IFsZSCxcCVv4e3rRPgPeEHIGqBjWlSn/view\",\n",
    "        \"es_02\": \"https://drive.google.com/file/d/1uSstet8XphpqKFyDsMbZmz17qFKdP2_2/view\",\n",
    "        \"es_03\": \"https://drive.google.com/file/d/1vD4MMFdLrYZmLSRE-rHpV0xCaxeJLsLR/view\",\n",
    "        \"es_04\": \"https://drive.google.com/file/d/1VGjIQQctVaTL8UWhzrLEasSaclZqufyT/view\",\n",
    "        \"es_05\": \"https://drive.google.com/file/d/1FOKWpniGwEiTc6UzLUxzfu9mTn8mpF-M/view\",\n",
    "        \"fr_01\": \"https://drive.google.com/file/d/17KkF1RbjR8-JrEfm9YuOnule8khSFxH7/view\",\n",
    "        \"fr_02\": \"https://drive.google.com/file/d/1ruZ1lszLJtHNMDBYxzTZK6x_pJa5iWxl/view\",\n",
    "        \"fr_03\": \"https://drive.google.com/file/d/1G-ORIK6Ktm9jhnJGtDk8Jyw4G0qmt7yr/view\",\n",
    "        \"fr_04\": \"https://drive.google.com/file/d/1Koo0L2CPQzkMRuhl_W09BgAhwSHcqTCx/view\",\n",
    "        \"fr_05\": \"https://drive.google.com/file/d/1m604W4o9d4aIxmhNej57bvKzfgHnqc7y/view\",\n",
    "    },\n",
    "    \"We Are Not the Same\": {\n",
    "        \"en_01\": \"https://drive.google.com/file/d/1D3ZWidzjKa0NDc1Si5Rs07XftUrGkzAn/view\",\n",
    "        \"en_02\": \"https://drive.google.com/file/d/1gmcUdLNJHFsZKnKViH6Jl9wTQWH3UHn1/view\",\n",
    "        \"en_03\": \"https://drive.google.com/file/d/1iELr3d4vZ6thCikmFo5e-6XpPZFSQJ1j/view\",\n",
    "        \"en_04\": \"https://drive.google.com/file/d/1PocN1DMjNxSBeHKcjBxPKoUcc2EPyYBk/view\",\n",
    "        \"en_05\": \"https://drive.google.com/file/d/1GxsrUOn7PgjvPa9_Ex8Xi0lvnSVZTeEC/view\",\n",
    "        \"es_01\": \"https://drive.google.com/file/d/12Q0fkncacj-MIBCustm8QIYj0L_bhL03/view\",\n",
    "        \"es_02\": \"https://drive.google.com/file/d/1VoK0sfK5f5fBI0QtORFEyme6JgT-JBNe/view\",\n",
    "        \"es_03\": \"https://drive.google.com/file/d/1M4rbwbFZVnMLAni21mSGgJGYyq4Ce8je/view\",\n",
    "        \"es_04\": \"https://drive.google.com/file/d/13ZmJgciXcuF7JJzQs7y7JYBmB-2Rw_DU/view\",\n",
    "        \"es_05\": \"https://drive.google.com/file/d/15XUaluFAIeiag5Uu5VcvkDkFJeXsIwU6/view\",\n",
    "        \"fr_01\": \"https://drive.google.com/file/d/1aS9OBXi1cBVc9yEqcALAl6XzagmOfS5M/view\",\n",
    "        \"fr_02\": \"https://drive.google.com/file/d/1exT3VjV9gWMmKZ0FAMswCCXNMRu5I6AC/view\",\n",
    "        \"fr_03\": \"https://drive.google.com/file/d/1Gu28aJRBdMf6u1ypA9eTjLbTIX5X2bxp/view\",\n",
    "        \"fr_04\": \"https://drive.google.com/file/d/1pqRH86PXeh3jQ8z2XFtO55dZ6b-k5WZY/view\",\n",
    "    },\n",
    "}\n",
    "templates_url = {\n",
    "    \"Distracted Boyfriend\": {\"template\": \"https://drive.google.com/file/d/1MbUrmwEktCRdgR-DqSE2gnnmF_V52uQq/view\"},\n",
    "    \"Traumatized Mr. Incredible\": {\"template\": \"https://drive.google.com/file/d/1coxx83BauTNvz9gM2731y5S96edHqvWU/view\"},\n",
    "    \"Spider-Man Pointing at Spider-Man\": {\"template\": \"https://drive.google.com/file/d/175oLkde389sEh1IPeTqgSNHBuyvsfyQA/view\"},\n",
    "    \"We Are Not the Same\": {\"template\": \"https://drive.google.com/file/d/1RGm1KO03J4Zr7IWJ_3ulTy4w0tqpuEwR/view\"},\n",
    "}\n",
    "\n",
    "# Function to fetch images locally\n",
    "def fetch_images_local(type_image: str):\n",
    "    for root, dirs, files in os.walk('./'+type_image):\n",
    "        try:\n",
    "            for file in files:\n",
    "                if file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "                    image_path = os.path.join(root, file)\n",
    "                    image = Image.open(image_path)\n",
    "                    yield image_path, image\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch image from {image_path}: {e}\")\n",
    "            continue\n",
    "                \n",
    "# Function to process images and add attributes\n",
    "def add_attributes(type_image, model, processor, device):\n",
    "    # Wrap the fetch_images generator with tqdm to track progress\n",
    "    if type_image == \"Memes\":\n",
    "        total_docs = 57\n",
    "    elif type_image == \"Templates\":\n",
    "        total_docs = 4\n",
    "    for doc, image in tqdm(fetch_images_local(type_image), desc=\"Assigning attributes\", total=total_docs):\n",
    "        try:\n",
    "            print(\"Trying to process\", doc)\n",
    "            print(\"Type image\", type_image)\n",
    "            image.show()\n",
    "            # Generate values\n",
    "            task_prompt = \"<MORE_DETAILED_CAPTION>\"\n",
    "            meme_description = generate_description(model, processor, image, task_prompt, device)\n",
    "            print(\"Description generated\", meme_description)\n",
    "            \n",
    "            # If it's a meme, the name of the meme will be the filename\n",
    "            # If it's a template, the name of the meme will be the folder name where the template is located\n",
    "            if type_image == \"Memes\":\n",
    "                print(\"Processing meme\")\n",
    "                meme_name = os.path.basename(doc).split('.')[0]\n",
    "                meme_lang = os.path.basename(doc).split('_')[0].upper()\n",
    "                template_name = os.path.basename(os.path.dirname(doc))\n",
    "                meme_url = memes_url[template_name][meme_name]\n",
    "                meme_context = None\n",
    "                \n",
    "                result = query_model_with_explanation_and_fitted_frames(meme_description, frames, meme_lang=meme_lang)\n",
    "                \n",
    "            else:\n",
    "                print(\"Processing template\")\n",
    "                meme_name = None\n",
    "                meme_lang = \"EN\"\n",
    "                template_name = os.path.basename(os.path.dirname(doc))\n",
    "                meme_url = templates_url[meme_name][\"template\"]\n",
    "                meme_context = meme_contexts.get(meme_name)\n",
    "                print(\"Meme context\", meme_context)\n",
    "                \n",
    "                result = query_model_with_explanation_and_fitted_frames(meme_description, frames, meme_context)               \n",
    "            \n",
    "            print(\"Result\", result)\n",
    "            # Extract values\n",
    "            explanation = result[\"explanation\"]\n",
    "            fitted_frames = result[\"fitted_frames\"]\n",
    "            \n",
    "            # Fitted frames is a dictionary, convert it to a list of dictionaries\n",
    "            # Each dictionary contains the frame name and the reasoning\n",
    "            fitted_frames = [{\"name\": frame, \"reasoning\": reasoning} for frame, reasoning in fitted_frames.items()]\n",
    "\n",
    "            # Insert the values in a MongoDB collection\n",
    "            if type_image == \"Memes\":\n",
    "                if meme_lang == \"EN\":\n",
    "                    collection = db['local-memes-en']\n",
    "                elif meme_lang == \"ES\":\n",
    "                    collection = db['local-memes-es']\n",
    "                elif meme_lang == \"FR\":\n",
    "                    collection = db['local-memes-fr']\n",
    "            else:\n",
    "                collection = db['local-templates']\n",
    "            \n",
    "            print(\"Collection to insert\", collection)\n",
    "            \n",
    "            if type_image == \"Memes\":\n",
    "                document_inserted = {\n",
    "                    \"name\": meme_name,\n",
    "                    \"template_name\": template_name,\n",
    "                    \"url\": meme_url,\n",
    "                    \"gen_description\": meme_description,\n",
    "                    \"gen_explanation\": explanation,\n",
    "                    \"gen_fitted_frames\": fitted_frames,\n",
    "                }\n",
    "            else:\n",
    "                document_inserted = {\n",
    "                    \"name\": template_name,\n",
    "                    \"url\": meme_url,\n",
    "                    \"context\": meme_context,\n",
    "                    \"gen_description\": meme_description,\n",
    "                    \"gen_explanation\": explanation,\n",
    "                    \"gen_fitted_frames\": fitted_frames,\n",
    "                }\n",
    "\n",
    "            collection.insert_one(\n",
    "                document_inserted\n",
    "            )\n",
    "                 \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process and insert document with name {doc}: {e}\")\n",
    "            continue\n",
    "        \n",
    "# Run the pipeline\n",
    "print(\"Starting the meme analysis pipeline...\")\n",
    "print(\"Loaded Frames:\", len(frames))\n",
    "#result_memes = add_attributes(\"Memes\", model, processor, device)\n",
    "#result_templates = add_attributes(\"Templates\", model, processor, device)\n",
    "\n",
    "\n",
    "#TODO\n",
    "# 1. Add the template description to the mmeme prompt and tell the model that the meme is based on that template\n",
    "# 2. Improve the prompts to be more specific"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
